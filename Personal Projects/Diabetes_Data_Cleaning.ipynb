{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Data Wrangling Step: Diabetes Data Set</h1></center>\n",
    "\n",
    "This notebook shows the steps our group took to clean and preprocess our data set for our group project in IST687.  We got this data set from [UCI Machine Learning Datasets Repository--Diabetes 130-US hospitals for years 1999-2008 Data Set](https://archive.ics.uci.edu/ml/datasets/diabetes+130-us+hospitals+for+years+1999-2008).  Our goal is to use the data provided to build a classifier that can predict whether someone admitted for diabetes will be readmitted in <30 days, >30days, or not readmitted.  \n",
    "\n",
    "This notebook details the steps taken to clean the data set so that machine learning alogrithms can be applied to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "pd.options.display.max_rows = 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Data Dictionary: Categorical Encodings</h2></center>\n",
    "\n",
    "**admission\\_type\\_id **|**description**\n",
    ":-----:|:-----:\n",
    "1 |Emergency\n",
    "2 |Urgent\n",
    "3 |Elective\n",
    "4 |Newborn\n",
    "5 |Not Available\n",
    "6 |NULL\n",
    "7 |Trauma Center\n",
    "8 |Not Mapped\n",
    " | \n",
    "**discharge\\_disposition\\_id** |**description**\n",
    "1 |Discharged to home\n",
    "2 |Discharged/transferred to another short term hospital\n",
    "3 |Discharged/transferred to SNF\n",
    "4 |Discharged/transferred to ICF\n",
    "5 |Discharged/transferred to another type of inpatient care institution\n",
    "6 |Discharged/transferred to home with home health service\n",
    "7 |Left AMA\n",
    "8 |Discharged/transferred to home under care of Home IV provider\n",
    "9 |Admitted as an inpatient to this hospital\n",
    "10 |Neonate discharged to another hospital for neonatal aftercare\n",
    "11 |Expired\n",
    "12 |Still patient or expected to return for outpatient services\n",
    "13 |Hospice / home\n",
    "14 |Hospice / medical facility\n",
    "15 |Discharged/transferred within this institution to Medicare approved swing bed\n",
    "16 |Discharged/transferred/referred another institution for outpatient services\n",
    "17 |Discharged/transferred/referred to this institution for outpatient services\n",
    "18 |NULL\n",
    "19 |Expired at home. Medicaid only, hospice.\n",
    "20 |Expired in a medical facility. Medicaid only, hospice.\n",
    "21 |Expired, place unknown. Medicaid only, hospice.\n",
    "22 |Discharged/transferred to another rehab fac including rehab units of a hospital .\n",
    "23 |Discharged/transferred to a long term care hospital.\n",
    "24 |Discharged/transferred to a nursing facility certified under Medicaid but not certified under Medicare.\n",
    "25 |Not Mapped\n",
    "26 |Unknown/Invalid\n",
    "30 |Discharged/transferred to another Type of Health Care Institution not Defined Elsewhere\n",
    "27 |Discharged/transferred to a federal health care facility.\n",
    "28 |Discharged/transferred/referred to a psychiatric hospital of psychiatric distinct part unit of a hospital\n",
    "29 |Discharged/transferred to a Critical Access Hospital (CAH).\n",
    " | \n",
    "**admission\\_source\\_id** |**description**\n",
    "1 |Physician Referral\n",
    "2 |Clinic Referral\n",
    "3 |HMO Referral\n",
    "4 |Transfer from a hospital\n",
    "5 |Transfer from a Skilled Nursing Facility (SNF)\n",
    "6 |Transfer from another health care facility\n",
    "7 |Emergency Room\n",
    "8 |Court/Law Enforcement\n",
    "9 |Not Available\n",
    "10 |Transfer from critial access hospital\n",
    "11 |Normal Delivery\n",
    "12 |Premature Delivery\n",
    "13 |Sick Baby\n",
    "14 |Extramural Birth\n",
    "15 |Not Available\n",
    "17 |NULL\n",
    "18 |Transfer From Another Home Health Agency\n",
    "19 |Readmission to Same Home Health Agency\n",
    "20 |Not Mapped\n",
    "21 |Unknown/Invalid\n",
    "22 |Transfer from hospital inpt/same fac reslt in a sep claim\n",
    "23 |Born inside this hospital\n",
    "24 |Born outside this hospital\n",
    "25 |Transfer from Ambulatory Surgery Center\n",
    "26 |Transfer from Hospice\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "<center><h1>Steps Taken During Data Cleaning</h1></center>\n",
    "\n",
    "-- (x) Convert `gender` values from strings to integers.  Male=0, Female=1.\n",
    "\n",
    "-- (x) Convert `diabetesMed` values from strings to integers.  No=0, Yes=1\n",
    "\n",
    "-- (x) Get list of column names for all categorical columns.  All medicine columns had the same possible values of `Down`, `No`, `Steady`, or `Up`.  Iterate through all columns and get unique values as a list. Sort the list.  If the list is equal to `['Down', 'No', 'Steady', 'Up']`, this is a medicine column, and needs to be one hot encoded.  Append column name to `one_hot_cols` array.  Also add `race` to this column.  When finished, create new one-hot encoded dataframe using `pd.get_dummies()` on the dataframe and list of column names.  \n",
    "\n",
    "-- (X) Drop encounterID.  \n",
    "\n",
    "-- (x) Change age category from current format to integer value.  E.G. Row 1, \\[10-20) becomes 15.  \n",
    "\n",
    "-- Deal with missing weight values \n",
    "\n",
    "-- Create correlation heatmap with labels\n",
    "\n",
    "-- Create Correlation heatmap between variables\n",
    "\n",
    "-- Decide if we should drop `patient_nbr` column.  If not, figure out how we are going to encode it, since the current format is a problem.  \n",
    "\n",
    "\n",
    "\n",
    "<center><h3>Step 1: Read in the data</h3></center>\n",
    "\n",
    "In this step, we read in the raw dataset, store it in a pandas dataframe, and store the labels as a separate series before dropping the column from the dataframe.  The labels were removed to make the data conversion steps easier, since we want to leave the columns encoded as strings for now.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data and remove labels for now.  Will add back in when dealing with null values.  \n",
    "\n",
    "raw_df = pd.read_csv(\"diabetic_data.csv\")\n",
    "\n",
    "# Remove labels and store in a separate variable. Will add back in after one hot encoding step\n",
    "labels = raw_df['readmitted']\n",
    "raw_df.drop('readmitted', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Step 2:  Recode Binary Categorical Columns</h3></center>\n",
    "\n",
    "The columns `gender`, `diabetesMed`, and `change` are categorical columns that contain only choices. These columns are currently encoded as strings.  Here, we replace the categorical values with 0s and 1s.  The mapping for the new encodings for each column is contained in the corresponding comment above each line of code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode gender column, Female = 0, Male = 1\n",
    "raw_df[\"gender\"] = (raw_df[\"gender\"].values == \"Female\" ).astype(np.uint8)\n",
    "\n",
    "# Recode diabetesMed column, No = 0, Yes = 1\n",
    "raw_df['diabetesMed'] = (raw_df[\"diabetesMed\"].values == \"Yes\").astype(np.uint8)\n",
    "\n",
    "# Recode change column, No = 0, Ch = 1\n",
    "raw_df[\"change\"] = (raw_df['change'].values == \"Ch\").astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Step 3: One-Hot Encoding Categorical Columns</h3></center>\n",
    "\n",
    "The strong majority of the columns in this data set are multicategoircal, and encoded as strings.  Some of these, such as `race`, were easy to identify.  However, because the of sheer amount of medicine columns, we scripted this step to make things easier.  We started by identifying that all columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for all medicine columns by checking the column's unique types.  Append any category name that fits\n",
    "\n",
    "categorical_cols = ['race', 'A1Cresult']\n",
    "for col in raw_df.columns.values:\n",
    "    target = ['Down', 'No', 'Steady', 'Up']\n",
    "    actual = list(sorted(raw_df[col].unique()))\n",
    "    if target == actual:\n",
    "        categorical_cols.append(col)\n",
    "\n",
    "# One hot encode the categorical columns using pd.get_dummies()\n",
    "other_cat_cols = ['max_glu_serum', 'acetohexamide', 'tolbutamide', 'troglitazone', \n",
    "                 'tolazamide', 'examide', 'citoglipton', 'glipizide-metformin', \n",
    "                 'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone']\n",
    "categorical_cols.extend(other_cat_cols)\n",
    "one_hot_df = pd.get_dummies(raw_df, columns=categorical_cols)\n",
    "age_str_vector = list(sorted(one_hot_df['age']))\n",
    "age_str_vector = age_str_vector[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Step 4: Convert Age column to integer values</h3></center>\n",
    "\n",
    "Age values are current stored as strings denoting binned ages. For instance, a 37 year old patient would show as \"\\[30-40)\".  Here, we replace all values with the median value for each bin--in this example case, patient's age would change to the integer 35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vector of integers that contain the average of the age bounds for each row.  \n",
    "age_int_vector = []\n",
    "for row in age_str_vector:\n",
    "    age = int(row[1] + '5')\n",
    "    age_int_vector.append(age)\n",
    "\n",
    "# Replace the age column with the new list containing corresponding integer values    \n",
    "one_hot_df['age'] = age_int_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Step 4: Drop Unneccesary Columns</h3></center>\n",
    "\n",
    "Here, we remove columns that contain information that is not useful, because of the format of the data, or because of excessive missing values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop encounter_id column\n",
    "\n",
    "one_hot_df.drop(['admission_type_id', 'discharge_disposition_id', 'admission_source_id', 'encounter_id', 'patient_nbr', 'payer_code', 'medical_specialty', 'weight'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Step 5: Strip letters from Diag Columns and cast to Floats</h3></center>\n",
    "\n",
    "Most values in these columns `Diag_1`, `Diag_2`, and `Diag_3` are able to be cast to floats without any changes, but some values are missing, and others contain the letter 'E' or 'V' which need to be removed before the data can be cast to a numeric type.  \n",
    "\n",
    "To deal with the null values, this required calculating the median of the column.  However, this cannot be done correctly until all other values are stripped of letters and cast to floats.  To accomplish this, we wrote a helper function that kept track of the indexes of null values dealing with all cases except for the null values.  Then, we calculated the median and replaced all the null values with this value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "float64\n",
      "False\n",
      "float64\n",
      "False\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "diags = ['diag_1', 'diag_2', 'diag_3']\n",
    "\n",
    "def update_diags(column):\n",
    "    column = list(column)\n",
    "    cleaned_column = []\n",
    "    all_values = []\n",
    "    nan_indexes = []\n",
    "    # Iterate through list\n",
    "    for ind, i in enumerate(column):\n",
    "        if i[0] == 'E' or i[0] == 'V':\n",
    "            cleaned_column.append(float(i[1:]))\n",
    "            all_values.append(float(i[1:]))\n",
    "        elif i == '?' or 'a' in i:\n",
    "            nan_indexes.append(ind)\n",
    "            cleaned_column.append(i)\n",
    "        else:\n",
    "            cleaned_column.append(float(i))\n",
    "            all_values.append(float(i))\n",
    "            \n",
    "    #get median value\n",
    "    median_val = np.median(all_values)\n",
    "    # Replace all nan values with median values\n",
    "    for n in nan_indexes:\n",
    "        cleaned_column[n] = median_val\n",
    "    # Cast column to a pandas Series and return it\n",
    "    return pd.Series(cleaned_column)\n",
    "    \n",
    "            \n",
    "for column in diags:\n",
    "    one_hot_df[column] = update_diags(one_hot_df[column])\n",
    "    print(one_hot_df[column].isna().any())\n",
    "    print(one_hot_df[column].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Final Step: Add Labels Back in and Export Dataset</h3></center>\n",
    "\n",
    "For the final step, we confirmed that there are no missing values left in the data set.  We then added the labels back in, and exported the newly cleaned and transformed data set as a .csv file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that no question mark values remain in the data set\n",
    "# print(one_hot_df.apply(lambda x: '?' in x.values, axis=1).any())\n",
    "\n",
    "# Check that no NaN Values remain in the dataset\n",
    "# one_hot_df.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add labels column back into dataframe and write to csv\n",
    "one_hot_df['labels'] = labels\n",
    "one_hot_df.to_csv(\"cleaned_diabetes_data_v2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
